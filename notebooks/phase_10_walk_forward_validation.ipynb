{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7b8ee1c",
   "metadata": {},
   "source": [
    "# Phase 10 — Walk-Forward Validation (Rolling-Origin Evaluation)\n",
    "\n",
    "While a single chronological split (70/15/15) provides a clean evaluation,\n",
    "real-world forecasting systems require performance stability across multiple time windows.\n",
    "\n",
    "In this phase, we implement walk-forward validation to simulate repeated forecasting cycles.\n",
    "\n",
    "The objective is to evaluate:\n",
    "\n",
    "- consistency across different forecast horizons\n",
    "- sensitivity to temporal drift\n",
    "- robustness under shifting data distributions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4934e29",
   "metadata": {},
   "source": [
    "## Why Walk-Forward?\n",
    "\n",
    "A single split may accidentally favor a model due to specific temporal patterns.\n",
    "\n",
    "Walk-forward validation:\n",
    "\n",
    "- trains on an expanding historical window\n",
    "- evaluates on the next fixed time block\n",
    "- repeats the process across time\n",
    "\n",
    "This mimics real operational deployment where models are periodically retrained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05b07d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "SRC = ROOT / \"src\"\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.append(str(SRC))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from energy_forecast.evaluate import root_mean_squared_error\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from energy_forecast.split import walk_forward_splits\n",
    "from energy_forecast.features import add_lag_features, add_rolling_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8dbf0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51864, 9),\n",
       "         Date  Start_Hour  End_Hour Source  Day_of_Year   Day_Name Month_Name  \\\n",
       " 0 2020-01-01          13        14  Solar            1  Wednesday    January   \n",
       " 1 2020-01-01          21        22   Wind            1  Wednesday    January   \n",
       " 2 2020-01-01          20        21   Wind            1  Wednesday    January   \n",
       " 3 2020-01-01           6         7   Wind            1  Wednesday    January   \n",
       " 4 2020-01-01          19        20   Wind            1  Wednesday    January   \n",
       " \n",
       "    Season  Production  \n",
       " 0  Winter        2179  \n",
       " 1  Winter        1228  \n",
       " 2  Winter        1268  \n",
       " 3  Winter        2293  \n",
       " 4  Winter        1181  )"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(ROOT / \"data\" / \"Energy Production Dataset.csv\")  \n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df = df.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "TARGET = \"Production\"\n",
    "TIME_COL = \"Date\"\n",
    "\n",
    "df.shape, df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35705eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (51864, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Start_Hour</th>\n",
       "      <th>End_Hour</th>\n",
       "      <th>Source</th>\n",
       "      <th>Day_of_Year</th>\n",
       "      <th>Day_Name</th>\n",
       "      <th>Month_Name</th>\n",
       "      <th>Season</th>\n",
       "      <th>Production</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>Solar</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>January</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>Wind</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>January</td>\n",
       "      <td>Winter</td>\n",
       "      <td>1228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>Wind</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>January</td>\n",
       "      <td>Winter</td>\n",
       "      <td>1268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>Wind</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>January</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>Wind</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>January</td>\n",
       "      <td>Winter</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Start_Hour  End_Hour Source  Day_of_Year   Day_Name Month_Name  \\\n",
       "0 2020-01-01          13        14  Solar            1  Wednesday    January   \n",
       "1 2020-01-01          21        22   Wind            1  Wednesday    January   \n",
       "2 2020-01-01          20        21   Wind            1  Wednesday    January   \n",
       "3 2020-01-01           6         7   Wind            1  Wednesday    January   \n",
       "4 2020-01-01          19        20   Wind            1  Wednesday    January   \n",
       "\n",
       "   Season  Production  \n",
       "0  Winter        2179  \n",
       "1  Winter        1228  \n",
       "2  Winter        1268  \n",
       "3  Winter        2293  \n",
       "4  Winter        1181  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Load dataset ---\n",
    "df = pd.read_csv(ROOT / \"data\" / \"Energy Production Dataset.csv\")\n",
    "\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df = df.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "TARGET = \"Production\"\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a135eab",
   "metadata": {},
   "source": [
    "## Strategy\n",
    "\n",
    "We use an expanding window approach:\n",
    "\n",
    "1. Train on initial historical block\n",
    "2. Predict next time window\n",
    "3. Expand training window forward\n",
    "4. Repeat evaluation\n",
    "\n",
    "This ensures that at every step:\n",
    "- only past data is used\n",
    "- no future information leaks backward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c0b7095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: (51864, 9)\n",
      "After features + dropna: (51840, 12)\n",
      "   Production_lag_1  Production_lag_24  Production_rollmean_24\n",
      "0            1775.0              950.0             1967.583333\n",
      "1            1267.0             2725.0             1929.583333\n",
      "2            4298.0             2308.0             2060.208333\n",
      "3            6857.0             1955.0             2294.750000\n",
      "4            3497.0             2617.0             2387.625000\n"
     ]
    }
   ],
   "source": [
    "df_feat = add_lag_features(df.copy(), target_col=TARGET, time_col=TIME_COL, lags=(1, 24))\n",
    "df_feat = add_rolling_features(df_feat, target_col=TARGET, time_col=TIME_COL, windows=(24,))\n",
    "\n",
    "# Lag/rolling create NaNs at the beginning; we must drop them\n",
    "df_feat = df_feat.dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"Original:\", df.shape)\n",
    "print(\"After features + dropna:\", df_feat.shape)\n",
    "\n",
    "# sanity check: these columns should exist\n",
    "cols_check = [f\"{TARGET}_lag_1\", f\"{TARGET}_lag_24\", f\"{TARGET}_rollmean_24\"]\n",
    "print(df_feat[cols_check].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4335cc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 25920, 5184), (2, 31104, 5184), (3, 36288, 5184), (4, 41472, 5184)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = walk_forward_splits(\n",
    "    df_feat,\n",
    "    time_col=TIME_COL,\n",
    "    initial_train_frac=0.50,\n",
    "    val_frac=0.10,\n",
    "    n_folds=4\n",
    ")\n",
    "\n",
    "[(f.fold, len(f.train), len(f.val)) for f in folds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c2f01cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hgb_pipeline(X: pd.DataFrame):\n",
    "    cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "    num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", \"passthrough\", num_cols),\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "    model = HistGradientBoostingRegressor(\n",
    "        random_state=42,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=8,\n",
    "        max_iter=500\n",
    "    )\n",
    "\n",
    "    return Pipeline(steps=[\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279767be",
   "metadata": {},
   "source": [
    "## Evaluation Metric\n",
    "\n",
    "For each walk-forward fold:\n",
    "\n",
    "- Compute RMSE\n",
    "- Record performance\n",
    "- Compare variance across folds\n",
    "\n",
    "Low variance indicates stable forecasting capability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "891c0f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE: 2313.870373780608\n",
      "Std RMSE: 175.62713952142477\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for f in folds:\n",
    "    train_df = f.train\n",
    "    val_df = f.val\n",
    "\n",
    "    X_train = train_df.drop(columns=[TARGET, TIME_COL])\n",
    "    y_train = train_df[TARGET]\n",
    "\n",
    "    X_val = val_df.drop(columns=[TARGET, TIME_COL])\n",
    "    y_val = val_df[TARGET]\n",
    "\n",
    "    pipe = make_hgb_pipeline(X_train)\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    preds = pipe.predict(X_val)\n",
    "    rmse = root_mean_squared_error(y_val, preds)\n",
    "\n",
    "    results.append({\n",
    "        \"fold\": f.fold,\n",
    "        \"train_rows\": len(train_df),\n",
    "        \"val_rows\": len(val_df),\n",
    "        \"rmse\": rmse\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n",
    "print(\"Mean RMSE:\", results_df[\"rmse\"].mean())\n",
    "print(\"Std RMSE:\", results_df[\"rmse\"].std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5219a2",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "If RMSE remains stable across folds:\n",
    "\n",
    "- The model generalizes consistently.\n",
    "- No major temporal drift is detected.\n",
    "- Forecasting reliability is confirmed.\n",
    "\n",
    "If variance is high:\n",
    "\n",
    "- The model may be sensitive to regime shifts.\n",
    "- Additional features or retraining frequency may be required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7161a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE: 2313.870373780608\n",
      "Std RMSE: 175.62713952142477\n",
      "Best fold RMSE: 2113.378633215558\n",
      "Worst fold RMSE: 2489.758458441334\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean RMSE:\", results_df[\"rmse\"].mean())\n",
    "print(\"Std RMSE:\", results_df[\"rmse\"].std())\n",
    "print(\"Best fold RMSE:\", results_df[\"rmse\"].min())\n",
    "print(\"Worst fold RMSE:\", results_df[\"rmse\"].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a8f446",
   "metadata": {},
   "source": [
    "#### Observation: \n",
    "\n",
    "The mean RMSE reflects expected performance under repeated temporal retraining.  \n",
    "Low standard deviation indicates stable behavior across folds.  \n",
    "The moderate best–worst gap suggests consistent performance with minor seasonal variability.  \n",
    "Overall, results confirm robustness beyond a single split.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51235d02",
   "metadata": {},
   "source": [
    "# Final Project Conclusion - Energy Production Forecasting\n",
    "\n",
    "This project developed a structured, leakage-safe time-series regression system to forecast hourly energy production using historical data.\n",
    "\n",
    "The workflow followed a disciplined, phase-driven methodology:\n",
    "\n",
    "- Problem framing with RMSE as the primary metric  \n",
    "- Strict chronological splitting (70/15/15)  \n",
    "- Baseline establishment (Mean, Ridge)  \n",
    "- Modular preprocessing pipelines  \n",
    "- Leakage-safe lag and rolling feature engineering  \n",
    "- Advanced ensemble model comparison  \n",
    "- Residual diagnostics and stability analysis  \n",
    "- Final model consolidation (Train + Validation → Test)\n",
    "\n",
    "---\n",
    "\n",
    "## Performance Progression\n",
    "\n",
    "Model performance improved systematically across phases:\n",
    "\n",
    "- **Mean Baseline RMSE:** ~4474  \n",
    "- **Ridge Regression RMSE:** ~4434  \n",
    "- **HistGradientBoosting (train-only) Test RMSE:** ~2381  \n",
    "- **Final Consolidated Model (Train + Val → Test): ~2339.96**\n",
    "\n",
    "Key insights:\n",
    "\n",
    "- Lag features (1-hour and 24-hour) significantly improved predictive strength.\n",
    "- Rolling mean features enhanced stability during volatile periods.\n",
    "- HistGradientBoosting effectively captured non-linear time interactions.\n",
    "- Retraining on Train + Validation improved generalization.\n",
    "\n",
    "---\n",
    "\n",
    "## Technical Strength Demonstrated\n",
    "\n",
    "This project emphasizes:\n",
    "\n",
    "- Strict leakage prevention discipline  \n",
    "- Proper train/validation/test separation  \n",
    "- Pipeline-based preprocessing  \n",
    "- Forecasting-specific feature engineering  \n",
    "- Ensemble modeling for non-linear patterns  \n",
    "- Residual diagnostics and robustness validation  \n",
    "\n",
    "The system reflects structured time-series modeling rather than ad-hoc experimentation.\n",
    "\n",
    "---\n",
    "\n",
    "## Deployment Readiness\n",
    "\n",
    "The project is structured for practical deployment:\n",
    "\n",
    "- Preprocessing and modeling are encapsulated within reusable pipelines.\n",
    "- Chronological validation simulates real-world future forecasting.\n",
    "- Final model is trained on all available historical data (Train + Validation).\n",
    "- Feature engineering logic is deterministic and reproducible.\n",
    "\n",
    "With minimal extension, this model can be:\n",
    "\n",
    "- Serialized using `joblib` or `pickle`\n",
    "- Exposed via a REST API (FastAPI / Flask)\n",
    "- Integrated into batch forecasting pipelines\n",
    "- Scheduled for periodic retraining as new data arrives\n",
    "\n",
    "The architecture supports productionization with limited refactoring.\n",
    "\n",
    "---\n",
    "\n",
    "## Limitations\n",
    "\n",
    "- No external exogenous variables (e.g., weather inputs)\n",
    "- No probabilistic prediction intervals\n",
    "- No rolling-origin cross-validation yet\n",
    "- No automated retraining pipeline\n",
    "\n",
    "---\n",
    "\n",
    "## Future Enhancements\n",
    "\n",
    "- Incorporate weather and external signals  \n",
    "- Implement walk-forward validation  \n",
    "- Add probabilistic forecasting  \n",
    "- Use SHAP for feature importance analysis  \n",
    "- Automate time-aware hyperparameter tuning  \n",
    "- Build lightweight inference API for real-time predictions  \n",
    "\n",
    "---\n",
    "\n",
    "## Closing Statement\n",
    "\n",
    "The final model demonstrates strong predictive performance, stable generalization, and disciplined evaluation under realistic time constraints.\n",
    "\n",
    "This project reflects intermediate-to-advanced capability in time-series regression, structured ML workflows, and deployment-aware system design.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8ec461",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
